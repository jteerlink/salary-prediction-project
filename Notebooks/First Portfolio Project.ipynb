{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be able to predict the salaries of various job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#your info here\n",
    "__author__ = \"Jared Teerlink\"\n",
    "__email__ = \"jteerlink@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 2 Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into a Pandas dataframe\n",
    "train_features = pd.read_csv('../Data/train_features.csv')\n",
    "train_salaries = pd.read_csv('../Data/train_salaries.csv')\n",
    "test_features = pd.read_csv('../Data/test_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 3 Clean the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for duplicate data, invalid data (e.g. salaries <=0), or corrupt data and remove it\n",
    "\n",
    "\n",
    "\n",
    "train_combined = train_features.merge(train_salaries, on = 'jobId', how = 'left')\n",
    "train_combined = train_combined[train_combined.salary > 0]\n",
    "# train_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "salary                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.drop(labels = ['jobId', 'companyId'],inplace=True,axis=1)\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "pandas_profiling.ProfileReport(train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_combined.milesFromMetropolis,train_combined.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.groupby(['jobType','degree'])['salary'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(train_num['degree_ord']), set(train_num['jobType_ord']))\n",
    "\n",
    "# degree 2-4 and type4-7 ==A\n",
    "# degree 0-1 and type4-7 ==B\n",
    "# degree 2-4 and type2-3 ==C\n",
    "# degree 0-1 and type2-3 ==D\n",
    "# degree 2-4 and type0-1 ==E\n",
    "# degree 0-1 and type0-1 ==F\n",
    "\n",
    "def reclassjob(df):\n",
    "    #some informative note should go here\n",
    "    if (2 <= df.degree_ord <= 4 and 4 <= df.jobType_ord <= 7):\n",
    "        return 5\n",
    "    elif (0 <= df.degree_ord <= 1 and 4 <= df.jobType_ord <= 7):\n",
    "        return 4\n",
    "    elif (2 <= df.degree_ord <= 4 and 2 <= df.jobType_ord <= 3):\n",
    "        return 3\n",
    "    elif (0 <= df.degree_ord <= 1 and 2 <= df.jobType_ord <= 3):\n",
    "        return 2\n",
    "    elif (2 <= df.degree_ord <= 4 and 0 <= df.jobType_ord <= 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num['customclass'] = train_num.apply(reclassjob,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize each feature variable\n",
    "#summarize the target variable\n",
    "#look for correlation between each feature and the target\n",
    "#look for correlation between features\n",
    "\n",
    "train_features.describe()\n",
    "\n",
    "train_features.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_combined.degree.groupby(train_combined['degree']).count()\n",
    "\n",
    "plt.bar(x.index,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['yearsExperience','milesFromMetropolis']\n",
    "cat_features = ['jobType','degree','industry']\n",
    "\n",
    "subsize = str(round(len(cat_features))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_bar(x,y):\n",
    "    data = x.groupby(x).count()  \n",
    "#     plt.bar(data.index,data)\n",
    "    plt.boxplot(data)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in cat_features:\n",
    "    cat_bar(train_combined[i],cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined[train_combined.salary>100].groupby(train_combined['jobType']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(train_combined.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_combined.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.dtypes\n",
    "# train_combined.corr()\n",
    "\n",
    "# drop major \n",
    "train_combined = train_combined.drop('major_enc',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare final data frames\n",
    "\n",
    "train_num = train_combined.select_dtypes(exclude = 'object')\n",
    "\n",
    "train_final = train_num.drop(['salary'],axis = 1)\n",
    "\n",
    "train_salary = train_combined['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_salary = pd.DataFrame(train_combined.salary.groupby(train_combined['jobType']).mean())\n",
    "\n",
    "\n",
    "\n",
    "avg_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_avg = train_combined.merge(avg_salary,how = 'left',left_on = 'jobType', right_on=avg_salary.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --Baseline Metric--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "963.9252996562975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(train_with_avg.salary_x,train_with_avg.salary_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy Variables\n",
    "# major = pd.get_dummies(train_combined['major'], prefix_sep='_', drop_first=True)\n",
    "\n",
    "industry = pd.get_dummies(train_combined['industry'], prefix_sep='_', drop_first=True)\n",
    "\n",
    "train_combined = pd.concat([train_combined, industry], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "# major_coded = label_enc.fit_transform(train_combined['major'])\n",
    "\n",
    "\n",
    "industry_coded = label_enc.fit_transform(train_combined['industry'])\n",
    "\n",
    "# train_combined = pd.concat([train_combined, major_coded, industry_coded], axis=1)\n",
    "\n",
    "# train_combined['major_enc'] = major_coded\n",
    "train_combined['industry_enc'] = industry_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding - degree and jobtype\n",
    "\n",
    "degree = [['NONE', 'HIGH_SCHOOL', 'BACHELORS', 'MASTERS', 'DOCTORAL']]\n",
    "degree_array = np.asarray(train_combined.degree).reshape(-1,1)\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder(categories=degree)\n",
    "degree_ord = enc.fit_transform(degree_array)\n",
    "\n",
    "train_combined['degree_ord'] = degree_ord\n",
    "# ordered by average salary\n",
    "titles = [['JANITOR', 'JUNIOR', 'SENIOR', 'MANAGER', 'VICE_PRESIDENT', 'CFO', 'CTO', 'CEO']]\n",
    "titles_array = np.asarray(train_combined.jobType).reshape(-1,1)\n",
    "\n",
    "enc = OrdinalEncoder(categories=titles)\n",
    "titles_ord = enc.fit_transform(titles_array)\n",
    "\n",
    "train_combined['jobType_ord'] = titles_ord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_num_features, test_num_features, train_num_label, test_num_label = train_test_split(train_final,train_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a reasonable metric (MSE in this case)\n",
    "#create an extremely simple model and measure its efficacy\n",
    "#e.g. use \"average salary\" for each industry as your model and then measure MSE\n",
    "#during 5-fold cross-validation\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression(n_jobs=-1)\n",
    "\n",
    "model = lm.fit(train_num_features,train_num_label)\n",
    "predict = model.predict(test_num_features)\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_num_label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.linear_model.ElasticNetCV\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "enr = ElasticNetCV(max_iter=10000,cv=5,n_jobs=-1)\n",
    "\n",
    "model = enr.fit(train_num_features,train_num_label)\n",
    "\n",
    "predict = model.predict(test_num_features)\n",
    "\n",
    "mean_squared_error(test_num_label,predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "489.4892428466449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=500,n_jobs = -1)\n",
    "model = rf.fit(train_num_features,train_num_label)\n",
    "predict = model.predict(test_num_features)\n",
    "mean_squared_error(test_num_label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "498.50002597691974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.ensemble.RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [250,500,750]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2',None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10,15,20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 6, 8]\n",
    "warm_start = [True,False]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'warm_start': warm_start\n",
    "               }\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_grid = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, cv = 3, verbose=3, n_jobs = 3,scoring='neg_mean_squared_error',n_iter=50)\n",
    "# Fit the random search model\n",
    "rf_grid.fit(train_num_features,train_num_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'warm_start': False,\n",
    " 'n_estimators': 500,\n",
    " 'min_samples_split': 20,\n",
    " 'min_samples_leaf': 8,\n",
    " 'max_features': 'log2',\n",
    " 'max_depth': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(train_num_features,label = train_num_label,nthread=-1)\n",
    "# param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "# num_round = 10\n",
    "bst = xgb.XGBRFRegressor(n_estimators=500,objective='reg:squarederror',n_jobs=-1)\n",
    "model = bst.fit(train_num_features,train_num_label)\n",
    "predict = model.predict(test_num_features)\n",
    "\n",
    "mean_squared_error(test_num_label,predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
