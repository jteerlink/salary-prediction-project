{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:21:15.113764Z",
     "start_time": "2020-02-04T15:21:09.437818Z"
    }
   },
   "outputs": [],
   "source": [
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler, OrdinalEncoder, LabelEncoder,KBinsDiscretizer,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,ElasticNetCV,RidgeCV\n",
    "from sklearn.model_selection import cross_validate,RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "__author__ = \"Jared Teerlink\"\n",
    "__email__ = \"jteerlink@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prep Data for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#load the data into a Pandas dataframe\n",
    "train_features = pd.read_csv('../Data/train_features.csv')\n",
    "train_salaries = pd.read_csv('../Data/train_salaries.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:25:15.021365Z",
     "start_time": "2020-02-04T15:25:13.764899Z"
    }
   },
   "outputs": [],
   "source": [
    "#look for duplicate data, invalid data (e.g. salaries <=0), or corrupt data and remove it\n",
    "\n",
    "train_combined = train_features.merge(train_salaries, on = 'jobId', how = 'left')\n",
    "train_combined = train_combined[train_combined.salary > 0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T16:26:46.920737Z",
     "start_time": "2020-02-04T16:26:46.619535Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = train_combined.select_dtypes(include=['int64', 'float64']).drop(['salary'],axis = 1).columns\n",
    "categorical_features = train_combined.select_dtypes(include=['object']).drop(['jobId','companyId','major'],axis=1).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_features)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:45:49.374309Z",
     "start_time": "2020-02-04T15:45:47.381879Z"
    }
   },
   "outputs": [],
   "source": [
    "#engineer potential features\n",
    "for cat in categorical_features:\n",
    "    cat_stats =train_combined['salary'].groupby(train_combined[cat]).agg({f'{cat}_mean':'mean',\n",
    "                                                                          f'{cat}_max':'max',\n",
    "                                                                          f'{cat}_min':'min',\n",
    "                                                                          f'{cat}_median':'median',\n",
    "                                                                          f'{cat}_std':'std'})\n",
    "    train_combined = train_combined.merge(cat_stats,how = 'left',left_on = cat, right_on=cat_stats.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:06:09.597901Z",
     "start_time": "2020-02-04T19:06:09.333706Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define dataframes for training and test sets\n",
    "features = train_combined.drop(train_combined.select_dtypes(include=['object']).columns,axis=1)\n",
    "target = train_combined['salary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:06:16.450237Z",
     "start_time": "2020-02-04T19:06:16.012630Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(features,target, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered Lists for ordinal encoding\n",
    "\n",
    "degrees = [['NONE', 'HIGH_SCHOOL', 'BACHELORS', 'MASTERS', 'DOCTORAL']]\n",
    "\n",
    "titles = [['JANITOR', 'JUNIOR', 'SENIOR', 'MANAGER', 'VICE_PRESIDENT', 'CFO', 'CTO', 'CEO']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T16:28:08.260419Z",
     "start_time": "2020-02-04T16:28:08.252437Z"
    }
   },
   "outputs": [],
   "source": [
    "#create transformer class to work with pandas df and ordinal encoder\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class PandasToNumpy(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data_inputs): \n",
    "        return np.asarray(data_inputs).reshape(-1,1)\n",
    "\n",
    "\n",
    "# set up pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "ordinal_transformer_degree = Pipeline(steps = [\n",
    "    ('convert',PandasToNumpy()),\n",
    "    ('ordinal', OrdinalEncoder(categories=degrees))\n",
    "])\n",
    "\n",
    "ordinal_transformer_title = Pipeline(steps = [\n",
    "    ('convert',PandasToNumpy()),\n",
    "    ('ordinal', OrdinalEncoder(categories=titles))\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features[:1]),\n",
    "        ('degree_ordinal',ordinal_transformer_degree,[1]),\n",
    "        ('title_ordinal',ordinal_transformer_title,[0])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T17:57:59.948687Z",
     "start_time": "2020-02-04T17:57:59.943698Z"
    }
   },
   "outputs": [],
   "source": [
    "lm = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', LinearRegression(n_jobs=-1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:06:23.144051Z",
     "start_time": "2020-02-04T19:06:21.444443Z"
    }
   },
   "outputs": [],
   "source": [
    "lm.fit(train_X,train_y)\n",
    "y_pred = lm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:06:25.694252Z",
     "start_time": "2020-02-04T19:06:25.684441Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_squared_error(test_y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE for linear regression\n",
    "1285.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Light GBM Model pipelines and parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T16:52:35.981936Z",
     "start_time": "2020-02-04T16:52:35.969870Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'regressor__n_estimators': [x for x in range(300,600,50)],\n",
    "          'regressor__num_leaves':[x for x in range(5,50,10)],\n",
    "#           'regressor__max_depth':[x for x in range(20,80,10)],\n",
    "          'regressor__learning_rate':[x for x in np.arange(.2,.35,.03)],\n",
    "          'regressor__max_bin': [x for x in range(100,400,10)],\n",
    "          'regressor__reg_alpha': [.1, .2, .3, .4, .5],\n",
    "          'regressor__reg_lambda': [.1, .2, .3, .4, .5, .6, .7],\n",
    "          'regressor__boosting_type': ['dart'],\n",
    "          'regressor__subsample_for_bin':[x for x in range(200000,350000,10000)],\n",
    "               'regressor__min_split_gain' : [x for x in np.arange(.01,.5,.05)],\n",
    "              'regressor__min_child_weight'  : [x for x in np.arange(.05,.5,.05)],\n",
    "              'regressor__min_child_samples' : [x for x in range(5,30,5)]\n",
    "#               'regressor__colsample_bytree'  : [x for x in np.arange(1.0,2.5,.5)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:28:46.224670Z",
     "start_time": "2020-02-04T18:28:46.219640Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', lgb.LGBMRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:28:47.904192Z",
     "start_time": "2020-02-04T18:28:47.900159Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_random = RandomizedSearchCV(estimator = lgb_reg, \n",
    "                               param_distributions = param_grid, \n",
    "                               n_iter = 3, \n",
    "                               cv = 5, \n",
    "                               verbose=0, \n",
    "                               n_jobs = -1,\n",
    "                               scoring = 'neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T20:10:22.295742Z",
     "start_time": "2020-02-04T19:06:51.245019Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_random.fit(train_X,train_y)\n",
    "# print(lgb_random.best_score_)\n",
    "# print(lgb_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE best score for Random Search\n",
    "355.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T20:10:26.707778Z",
     "start_time": "2020-02-04T20:10:22.300731Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_best = lgb_random.best_estimator_\n",
    "ypred = lgb_best.predict(test_X)\n",
    "print(mean_squared_error(test_y,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSE for LGB Model\n",
    "356.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T20:18:08.935648Z",
     "start_time": "2020-02-04T20:18:08.760131Z"
    }
   },
   "outputs": [],
   "source": [
    "#save model for later import\n",
    "import joblib\n",
    "joblib.dump(lgb_random.best_estimator_, 'lightgbm.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T18:06:38.468099Z",
     "start_time": "2020-02-04T18:06:38.439218Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#read in \n",
    "\n",
    "import joblib\n",
    "lgbm = joblib.load('lightgbm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T19:04:08.121625Z",
     "start_time": "2020-02-04T19:04:04.385914Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ypred = lgbm.predict(test_X)\n",
    "print(mean_squared_error(test_y,ypred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
