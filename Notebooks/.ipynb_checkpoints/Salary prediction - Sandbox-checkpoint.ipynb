{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be able to predict the salaries of various job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import your libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "# import sklearn as sk\n",
    "#etc\n",
    "\n",
    "#your info here\n",
    "__author__ = \"Jared Teerlink\"\n",
    "__email__ = \"jteerlink@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 2 Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into a Pandas dataframe\n",
    "train_features = pd.read_csv('../Data/train_features.csv')\n",
    "train_salaries = pd.read_csv('../Data/train_salaries.csv')\n",
    "# test_features = pd.read_csv('../Data/test_features.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 3 Clean the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>companyId</th>\n",
       "      <th>jobType</th>\n",
       "      <th>degree</th>\n",
       "      <th>major</th>\n",
       "      <th>industry</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362684407687</td>\n",
       "      <td>COMP37</td>\n",
       "      <td>CFO</td>\n",
       "      <td>MASTERS</td>\n",
       "      <td>MATH</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362684407688</td>\n",
       "      <td>COMP19</td>\n",
       "      <td>CEO</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>WEB</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362684407689</td>\n",
       "      <td>COMP52</td>\n",
       "      <td>VICE_PRESIDENT</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362684407690</td>\n",
       "      <td>COMP38</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362684407691</td>\n",
       "      <td>COMP7</td>\n",
       "      <td>VICE_PRESIDENT</td>\n",
       "      <td>BACHELORS</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId companyId         jobType       degree      major  \\\n",
       "0  JOB1362684407687    COMP37             CFO      MASTERS       MATH   \n",
       "1  JOB1362684407688    COMP19             CEO  HIGH_SCHOOL       NONE   \n",
       "2  JOB1362684407689    COMP52  VICE_PRESIDENT     DOCTORAL    PHYSICS   \n",
       "3  JOB1362684407690    COMP38         MANAGER     DOCTORAL  CHEMISTRY   \n",
       "4  JOB1362684407691     COMP7  VICE_PRESIDENT    BACHELORS    PHYSICS   \n",
       "\n",
       "  industry  yearsExperience  milesFromMetropolis  salary  \n",
       "0   HEALTH               10                   83     130  \n",
       "1      WEB                3                   73     101  \n",
       "2   HEALTH               10                   38     137  \n",
       "3     AUTO                8                   17     142  \n",
       "4  FINANCE                8                   16     163  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look for duplicate data, invalid data (e.g. salaries <=0), or corrupt data and remove it\n",
    "\n",
    "\n",
    "\n",
    "train_combined = train_features.merge(train_salaries, on = 'jobId', how = 'left')\n",
    "train_combined = train_combined[train_combined.salary > 0]\n",
    "train_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.drop(labels = ['jobId','companyId','major'],inplace=True,axis=1)\n",
    "                      \n",
    "# train_combined = train_combined.drop(,inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy Variables\n",
    "# major = pd.get_dummies(train_combined['major'], prefix_sep='_', drop_first=True)\n",
    "\n",
    "industry = pd.get_dummies(train_combined['industry'], prefix_sep='_', drop_first=True)\n",
    "\n",
    "train_combined = pd.concat([train_combined, industry], axis=1)\n",
    "\n",
    "\n",
    "# major = pd.get_dummies(train_combined['major'], prefix_sep='_', drop_first=True)\n",
    "\n",
    "# train_combined = pd.concat([train_combined, major], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "# major_coded = label_enc.fit_transform(train_combined['major'])\n",
    "# \n",
    "\n",
    "# industry_coded = label_enc.fit_transform(train_combined['industry'])\n",
    "# company_coded = label_enc.fit_transform(train_combined['companyId'])\n",
    "\n",
    "\n",
    "# train_combined['major_enc'] = major_coded\n",
    "\n",
    "# train_combined = pd.concat([train_combined, major_coded], axis=1)\n",
    "# train_combined['industry_enc'] = industry_coded\n",
    "\n",
    "# train_combined['company_enc'] = company_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Encoding - degree and jobtype\n",
    "\n",
    "degree = [['NONE', 'HIGH_SCHOOL', 'BACHELORS', 'MASTERS', 'DOCTORAL']]\n",
    "degree_array = np.asarray(train_combined.degree).reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "enc = OrdinalEncoder(categories=degree)\n",
    "degree_ord = enc.fit_transform(degree_array)\n",
    "\n",
    "train_combined['degree_ord'] = degree_ord\n",
    "# ordered by average salary\n",
    "titles = [['JANITOR', 'JUNIOR', 'SENIOR', 'MANAGER', 'VICE_PRESIDENT', 'CFO', 'CTO', 'CEO']]\n",
    "titles_array = np.asarray(train_combined.jobType).reshape(-1,1)\n",
    "\n",
    "enc = OrdinalEncoder(categories=titles)\n",
    "titles_ord = enc.fit_transform(titles_array)\n",
    "\n",
    "train_combined['jobType_ord'] = titles_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# scl = StandardScaler()\n",
    "\n",
    "# # train_combined['yearsExperience'] = scl.fit_transform(np.asarray(train_combined['yearsExperience']).reshape(-1,1))\n",
    "# train_combined['milesFromMetropolis'] = scl.fit_transform(np.asarray(train_combined['milesFromMetropolis']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "train_poly = poly.fit_transform(train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare final data frames\n",
    "\n",
    "train_num = train_combined.select_dtypes(exclude = 'object')\n",
    "train_final = train_num.drop(['salary'],axis=1)\n",
    "\n",
    "train_salary = train_combined['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_num_features, test_num_features, train_num_label, test_num_label = train_test_split(train_poly,train_salary, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a reasonable metric (MSE in this case)\n",
    "#create an extremely simple model and measure its efficacy\n",
    "#e.g. use \"average salary\" for each industry as your model and then measure MSE\n",
    "#during 5-fold cross-validation\n",
    "\n",
    "\n",
    "\n",
    "lm = LinearRegression(n_jobs=-1)\n",
    "\n",
    "model = lm.fit(train_num_features,train_num_label)\n",
    "predict = model.predict(test_num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386.3125052620002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mean_squared_error(test_num_label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "410.3944048673012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <th>industry_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>749996.000000</td>\n",
       "      <td>749996.000000</td>\n",
       "      <td>749996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.994971</td>\n",
       "      <td>49.534714</td>\n",
       "      <td>3.001663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.212770</td>\n",
       "      <td>28.878453</td>\n",
       "      <td>2.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       yearsExperience  milesFromMetropolis   industry_enc\n",
       "count    749996.000000        749996.000000  749996.000000\n",
       "mean         11.994971            49.534714       3.001663\n",
       "std           7.212770            28.878453       2.000710\n",
       "min           0.000000             0.000000       0.000000\n",
       "25%           6.000000            25.000000       1.000000\n",
       "50%          12.000000            50.000000       3.000000\n",
       "75%          18.000000            75.000000       5.000000\n",
       "max          24.000000            99.000000       6.000000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression or ElasticNet to help alleviate difficulty in predicting less frequent jobtypes\n",
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainstorm 3 models that you think may improve results over the baseline model based on your EDA and explain why they're reasonable solutions here.\n",
    "\n",
    "Also write down any new features that you think you should try adding to the model based on your EDA, e.g. interaction variables, summary statistics for each group, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will cycle through creating features, tuning models, and training/validing models (steps 7-9) until you've reached your efficacy goal\n",
    "\n",
    "#### Your metric will be MSE and your goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that data is ready for modeling\n",
    "#create any new features needed to potentially enhance model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386.312506303153"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sklearn.linear_model.ElasticNetCV\n",
    "\n",
    "\n",
    "\n",
    "enr = RidgeCV(cv=5)\n",
    "\n",
    "model = enr.fit(train_num_features,train_num_label)\n",
    "\n",
    "predict = model.predict(test_num_features)\n",
    "\n",
    "mean_squared_error(test_num_label,predict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "489.4892428466449"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498.50002597691974"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestRegressor(n_estimators=500,n_jobs = -1)\n",
    "model = rf.fit(train_num_features,train_num_label)\n",
    "predict = model.predict(test_num_features)\n",
    "mean_squared_error(test_num_label,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "498.50002597691974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-31b4ec8aad3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "rf.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 33.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [100, 250, 500], 'max_features': ['sqrt', 'log2', None], 'max_depth': [30, 104, 178, 252, 326, 400, None], 'min_samples_split': [10, 15, 20, 25, 30], 'min_samples_leaf': [50, 75, 100, 200, 300, 400], 'warm_start': [False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn.ensemble.RandomForestRegressor\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100,250,500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt','log2',None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(30, 400, num = 6)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [10,15,20,25,30]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [50,75,100,200,300,400]\n",
    "warm_start = [False]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'warm_start': warm_start\n",
    "               }\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_grid = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, cv = 3, verbose=3, n_jobs = -1,scoring='neg_mean_squared_error',n_iter=10)\n",
    "# Fit the random search model\n",
    "rf_grid.fit(train_num_features,train_num_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': False,\n",
       " 'n_estimators': 250,\n",
       " 'min_samples_split': 30,\n",
       " 'min_samples_leaf': 50,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dummy var\n",
    "\n",
    "{'warm_start': False,\n",
    " 'n_estimators': 500,\n",
    " 'min_samples_split': 20,\n",
    " 'min_samples_leaf': 8,\n",
    " 'max_features': 'log2',\n",
    " 'max_depth': 30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with label encoding only\n",
    "\n",
    "{'warm_start': False,\n",
    " 'n_estimators': 750,\n",
    " 'min_samples_split': 20,\n",
    " 'min_samples_leaf': 8,\n",
    " 'max_features': 'log2',\n",
    " 'max_depth': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "717.034990487379"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(train_num_features,label = train_num_label,nthread=-1)\n",
    "# param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n",
    "# num_round = 10\n",
    "bst = xgb.XGBRFRegressor(n_estimators=500,objective='reg:squarederror',n_jobs=-1)\n",
    "model = bst.fit(train_num_features,train_num_label)\n",
    "predict = model.predict(test_num_features)\n",
    "\n",
    "mean_squared_error(test_num_label,predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'warm_start': False,\n",
    " 'n_estimators': 250,\n",
    " 'min_samples_split': 30,\n",
    " 'min_samples_leaf': 50,\n",
    " 'max_features': 'log2',\n",
    " 'max_depth': 30}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do 5-fold cross validation on models and measure MSE\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(warm_start = False, n_estimators=250, min_samples_split= 30, min_samples_leaf= 50, max_features= None, max_depth=30)\n",
    "\n",
    "cv = cross_validate(rf,train_num_features,train_num_label, scoring = 'neg_mean_squared_error',cv = 5,n_jobs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([544.82299995, 542.27099991, 542.41199994, 445.81500006,\n",
       "        445.58399987]),\n",
       " 'score_time': array([8.05800009, 8.15799999, 8.21199989, 7.31799984, 7.31800032]),\n",
       " 'test_score': array([-385.93969026, -384.86865774, -387.55273776, -386.2387099 ,\n",
       "        -384.72555811]),\n",
       " 'train_score': array([-364.49850353, -364.59984675, -363.76759415, -364.43073224,\n",
       "        -364.49207162])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train_X = lgb.Dataset(train_num_features)\n",
    "lgb_train_y = lgb.Dataset(train_num_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LGBMModel.get_params of LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_round = 300\n",
    "\n",
    "#  'min_split_gain' : [x for x in np.arange(.1,.25,.01)],\n",
    "# #               'min_child_weight'  : [x for x in np.arange(.1,.25,.01)],\n",
    "#               'min_child_samples' : [x for x in range(10,90,5)]\n",
    "# #               'colsample_bytree'  : [x for x in np.arange(.1,.25,.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [x for x in range(300,600,50)],\n",
    "          'num_leaves':[x for x in range(5,50,10)],\n",
    "#           'max_depth':[x for x in range(20,80,10)],\n",
    "          'learning_rate':[x for x in np.arange(.2,.35,.03)],\n",
    "          'max_bin': [x for x in range(100,400,10)],\n",
    "          'reg_alpha': [.1, .2, .3, .4, .5],\n",
    "          'reg_lambda': [.1, .2, .3, .4, .5, .6, .7],\n",
    "          'boosting_type': ['dart'],\n",
    "          'subsample_for_bin':[x for x in range(200000,350000,10000)],\n",
    "               'min_split_gain' : [x for x in np.arange(.01,.5,.05)],\n",
    "              'min_child_weight'  : [x for x in np.arange(.05,.5,.05)],\n",
    "              'min_child_samples' : [x for x in range(5,30,5)]\n",
    "#               'colsample_bytree'  : [x for x in np.arange(1.0,2.5,.5)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  15 out of  15 | elapsed: 31.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=3,\n",
       "          param_distributions={'n_estimators': [300, 350, 400, 450, 500, 550], 'num_leaves': [5, 15, 25, 35, 45], 'learning_rate': [0.2, 0.23, 0.26, 0.29000000000000004, 0.32], 'max_bin': [100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 3...00000002, 0.2, 0.25, 0.3, 0.35000000000000003, 0.4, 0.45], 'min_child_samples': [5, 10, 15, 20, 25]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='neg_mean_squared_error',\n",
       "          verbose=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lgb_random = RandomizedSearchCV(estimator = lgbm, \n",
    "                               param_distributions = param_grid, \n",
    "                               n_iter = 5, \n",
    "                               cv = 3, \n",
    "                               verbose=3, \n",
    "                               n_jobs = 3,\n",
    "                               scoring = 'neg_mean_squared_error')\n",
    "# Fit the random search model\n",
    "lgb_random.fit(train_num_features,train_num_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgb_best = lgb_random.best_estimator_\n",
    "# lgb_best.predict(X_test)\n",
    "ypred = lgb_best.predict(test_num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_for_bin': 290000, 'reg_lambda': 0.2, 'reg_alpha': 0.3, 'num_leaves': 15, 'n_estimators': 400, 'min_split_gain': 0.21000000000000002, 'min_child_weight': 0.4, 'min_child_samples': 15, 'max_bin': 360, 'learning_rate': 0.23, 'boosting_type': 'dart'}\n",
      "380.23056931807747\n"
     ]
    }
   ],
   "source": [
    "print(lgb_random.best_params_)\n",
    "print(mean_squared_error(test_num_label,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'subsample_for_bin': 280000, 'reg_lambda': 0.5, 'reg_alpha': 0.3, 'num_leaves': 25, 'n_estimators': 500, 'min_split_gain': 0.060000000000000005, 'min_child_weight': 0.05, 'min_child_samples': 25, 'max_bin': 210, 'learning_rate': 0.27, 'boosting_type': 'dart'}\n",
    "353.8570277502128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the model with the lowest error as your \"prodcuction\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write script that trains model on entire training set, saves model to disk,\n",
    "#and scores the \"test\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file or optionally save them as a table in a SQL database\n",
    "#additionally, you want to save a visualization and summary of your prediction and feature importances\n",
    "#these visualizations and summaries will be extremely useful to business stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
